{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfc85b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\costi\\Desktop\\4Y1S\\IAS_Personal_Proj\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import spearmanr # Para a estabilidade SHAP\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shap # Certifique-se de que a biblioteca SHAP está instalada\n",
    "# from aif360.metrics import ClassificationMetric # Ignorando por enquanto, usando cálculo manual de EOD\n",
    "\n",
    "# Define o nome da coluna sensível para uso consistente\n",
    "SENSITIVE_FEATURE_NAME = 'Q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee05732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_and_combine_data(directory_path):\n",
    "    \"\"\"Carrega X e y, limpa o cabeçalho e retorna X_train, y_train, X_test, y_test.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Carregar X: assumindo cabeçalho correto\n",
    "        X_train = pd.read_csv(f\"{directory_path}/X_train.csv\")\n",
    "        X_test = pd.read_csv(f\"{directory_path}/X_test.csv\")\n",
    "        \n",
    "        # Carregar Y: Pulando o cabeçalho 'Y' dentro do arquivo (skiprows=1)\n",
    "        y_train = pd.read_csv(f\"{directory_path}/y_train.csv\", \n",
    "                              header=None, \n",
    "                              names=['Y'], \n",
    "                              skiprows=1)\n",
    "                             \n",
    "        y_test = pd.read_csv(f\"{directory_path}/y_test.csv\", \n",
    "                             header=None, \n",
    "                             names=['Y'], \n",
    "                             skiprows=1)\n",
    "\n",
    "        # 1. Limpeza e Conversão para Numérico (Essencial após skiprows)\n",
    "        y_train['Y'] = pd.to_numeric(y_train['Y'].squeeze(), errors='coerce') \n",
    "        y_test['Y'] = pd.to_numeric(y_test['Y'].squeeze(), errors='coerce') \n",
    "\n",
    "        # 2. Verificar o Alinhamento (Safety Check)\n",
    "        if len(X_train) != len(y_train) or len(X_test) != len(y_test):\n",
    "             print(f\"ERRO: Desalinhamento de tamanho. Treino: {len(X_train)} vs {len(y_train)}. Teste: {len(X_test)} vs {len(y_test)}.\")\n",
    "             return None, None, None, None # Retorna None se falhar\n",
    "        \n",
    "        # 3. Retornar no formato correto para model.fit()\n",
    "        # y_train e y_test são Series 1D\n",
    "        return X_train, y_train['Y'].values.ravel(), X_test, y_test['Y'].values.ravel()\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Erro ao carregar arquivos no caminho {directory_path}: {e}\")\n",
    "        return None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b51db755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "from scipy.stats import spearmanr\n",
    "import shap \n",
    "\n",
    "SENSITIVE_FEATURE_NAME = 'Q' \n",
    "\n",
    "def run_experiment(X_train, y_train, X_test, y_test, baseline_feature_ranking=None):\n",
    "    \"\"\"Treina o modelo e calcula métricas usando os arrays X e y separados.\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # --- 1. Model Training ---\n",
    "    # y_train já deve estar no formato 1D (ravel)\n",
    "    model = LogisticRegression(solver='liblinear', random_state=42, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # --- 2. Robustness Metrics ---\n",
    "    results['Overall_Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    results['Overall_F1_Score'] = f1_score(y_test, y_pred)\n",
    "    results['AUROC'] = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    # --- 3. Fairness Metrics (EOD) ---\n",
    "    Q_test = X_test[SENSITIVE_FEATURE_NAME]\n",
    "    \n",
    "    # Cálculo do True Positive Rate (TPR)\n",
    "    # Grupo Privilegiado (Q=0)\n",
    "    TP_P = ((y_test == 1) & (Q_test == 0) & (y_pred == 1)).sum()\n",
    "    P_pos = ((y_test == 1) & (Q_test == 0)).sum()\n",
    "    TPR_P = TP_P / P_pos if P_pos > 0 else 0\n",
    "    \n",
    "    # Grupo Desprivilegiado (Q=1)\n",
    "    TP_U = ((y_test == 1) & (Q_test == 1) & (y_pred == 1)).sum()\n",
    "    U_pos = ((y_test == 1) & (Q_test == 1)).sum()\n",
    "    TPR_U = TP_U / U_pos if U_pos > 0 else 0\n",
    "\n",
    "    results['Equal_Opportunity_Difference'] = TPR_P - TPR_U\n",
    "    \n",
    "    # --- 4. Explainability Metrics (SHAP Stability) ---\n",
    "    explainer = shap.Explainer(model, X_train)\n",
    "    shap_values = explainer(X_test.sample(n=min(500, len(X_test)), random_state=42)) \n",
    "    \n",
    "    mean_abs_shap = pd.Series(np.abs(shap_values.values).mean(axis=0), index=X_test.columns)\n",
    "    current_feature_ranking = mean_abs_shap.sort_values(ascending=False).rank(method='first')\n",
    "\n",
    "    results['Feature_Importance_Ranking'] = current_feature_ranking.to_dict()\n",
    "\n",
    "    if baseline_feature_ranking is not None:\n",
    "        I_base = pd.Series(baseline_feature_ranking)\n",
    "        I_current = current_feature_ranking\n",
    "        common_features = I_base.index.intersection(I_current.index)\n",
    "        \n",
    "        rho, _ = spearmanr(I_base.loc[common_features].values, \n",
    "                           I_current.loc[common_features].values)\n",
    "        results['SHAP_Rank_Stability'] = rho\n",
    "    else:\n",
    "        results['SHAP_Rank_Stability'] = 1.0 \n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "307ffd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Loop de Auditoria ---\n",
      "\n",
      "Processando: baseline\n",
      "-> Linha de Base estabelecida.\n",
      "   -> EOD: 0.000 | F1: 0.000 | Estabilidade SHAP: 1.000\n",
      "\n",
      "Processando: bias_lq_0.1\n",
      "   -> EOD: 0.012 | F1: 0.867 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: bias_lq_0.3\n",
      "   -> EOD: 0.027 | F1: 0.873 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: bias_lq_0.5\n",
      "   -> EOD: 0.062 | F1: 0.877 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: bias_lq_0.7\n",
      "   -> EOD: 0.075 | F1: 0.884 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: bias_lq_0.9\n",
      "   -> EOD: 0.053 | F1: 0.885 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: noise_sy_0.1\n",
      "   -> EOD: -0.010 | F1: 0.870 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: noise_sy_0.2\n",
      "   -> EOD: -0.030 | F1: 0.869 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: noise_sy_0.3\n",
      "   -> EOD: -0.026 | F1: 0.870 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: noise_sy_0.4\n",
      "   -> EOD: -0.035 | F1: 0.869 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: imbalance_pu_0.2\n",
      "   -> EOD: 0.026 | F1: 0.842 | Estabilidade SHAP: 0.000\n",
      "\n",
      "Processando: imbalance_pu_0.4\n",
      "   -> EOD: 0.017 | F1: 0.852 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: imbalance_pu_0.6\n",
      "   -> EOD: -0.005 | F1: 0.863 | Estabilidade SHAP: -0.400\n",
      "\n",
      "Processando: imbalance_pu_0.8\n",
      "   -> EOD: 0.011 | F1: 0.872 | Estabilidade SHAP: -0.400\n",
      "\n",
      "--- Loop Concluído ---\n",
      "Resultados salvos em: project_audit_results.csv\n"
     ]
    }
   ],
   "source": [
    "# --- LOOP PRINCIPAL DE EXECUÇÃO ---\n",
    "\n",
    "# Lista de diretórios de experimentos (substitua pelos seus caminhos reais)\n",
    "experiment_directories = [\n",
    "    'datasets/baseline',\n",
    "    # Bias Series (l_q)\n",
    "    'datasets/bias_lq_0.1', \n",
    "    'datasets/bias_lq_0.3',\n",
    "    'datasets/bias_lq_0.5',\n",
    "    'datasets/bias_lq_0.7',\n",
    "    'datasets/bias_lq_0.9',\n",
    "    # Noise Series (sy)\n",
    "    'datasets/noise_sy_0.1',\n",
    "    'datasets/noise_sy_0.2',\n",
    "    'datasets/noise_sy_0.3',\n",
    "    'datasets/noise_sy_0.4',\n",
    "    # Imbalance Series (p_u)\n",
    "    'datasets/imbalance_pu_0.2',\n",
    "    'datasets/imbalance_pu_0.4',\n",
    "    'datasets/imbalance_pu_0.6',\n",
    "    'datasets/imbalance_pu_0.8'\n",
    "]\n",
    "\n",
    "master_results_df = pd.DataFrame()\n",
    "baseline_ranking = None\n",
    "\n",
    "print(\"--- Iniciando Loop de Auditoria ---\")\n",
    "\n",
    "for i, dir_path in enumerate(experiment_directories):\n",
    "    print(f\"\\nProcessando: {dir_path.split('/')[-1]}\")\n",
    "    \n",
    "    # CHAMA A FUNÇÃO E ESPERA 4 VALORES\n",
    "    X_train, y_train, X_test, y_test = load_and_combine_data(dir_path)\n",
    "    \n",
    "    # Se a função de carregamento falhar, pular\n",
    "    if X_train is None:\n",
    "        continue\n",
    "    \n",
    "    # Determinar se é a linha de base\n",
    "    is_baseline = (i == 0)\n",
    "\n",
    "    # Executar o experimento\n",
    "    current_results = run_experiment(X_train, y_train, X_test, y_test, \n",
    "                                     baseline_feature_ranking=baseline_ranking)\n",
    "    \n",
    "    # Se for a Linha de Base, capturar o ranking para uso futuro\n",
    "    if is_baseline:\n",
    "        baseline_ranking = current_results['Feature_Importance_Ranking']\n",
    "        print(\"-> Linha de Base estabelecida.\")\n",
    "\n",
    "    # Adicionar metadados ao resultado\n",
    "    current_results['Condition'] = 'Baseline' if is_baseline else dir_path.split('/')[-1].split('_')[0]\n",
    "    current_results['Parameter_Value'] = 'N/A' if is_baseline else dir_path.split('_')[-1]\n",
    "    \n",
    "    # Converter para DataFrame de uma linha e anexar ao mestre\n",
    "    results_row = pd.DataFrame([current_results])\n",
    "    master_results_df = pd.concat([master_results_df, results_row], ignore_index=True)\n",
    "    \n",
    "    print(f\"   -> EOD: {current_results['Equal_Opportunity_Difference']:.3f} | F1: {current_results['Overall_F1_Score']:.3f} | Estabilidade SHAP: {current_results['SHAP_Rank_Stability']:.3f}\")\n",
    "\n",
    "# Remover o ranking SHAP complexo para simplificar o arquivo final\n",
    "master_results_df = master_results_df.drop(columns=['Feature_Importance_Ranking'], errors='ignore')\n",
    "\n",
    "# Salvar a tabela final\n",
    "MASTER_RESULTS_FILE = 'project_audit_results.csv'\n",
    "master_results_df.to_csv(MASTER_RESULTS_FILE, index=False)\n",
    "print(\"\\n--- Loop Concluído ---\")\n",
    "print(f\"Resultados salvos em: {MASTER_RESULTS_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
